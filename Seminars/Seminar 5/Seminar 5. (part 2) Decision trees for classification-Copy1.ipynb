{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video https://youtu.be/AEHEPOgzDaI\n",
    "\n",
    "\n",
    "# Decision tree (classification) algorithm\n",
    "---\n",
    "- **Traininig**:\n",
    "    1. Find most *informative* combination of `node of the tree`,  `feature`, and  `split value`\n",
    "    2. Do split if `max_depth` is not reached\n",
    "    3. Iterate over 1-2.\n",
    "    \n",
    "    \n",
    "- **Inference** (prediction):\n",
    "    - Follow the rules ^_^.\n",
    "    \n",
    "\n",
    "## Decision tree example\n",
    "\n",
    "![](https://downloader.disk.yandex.ru/preview/4cdfaa21b0ba0cfdece332ce8fd8564dec5c2bc1b015cb4d29bc3b7eea15b43c/5f67b4b9/_F43xsaK0laj5sdgYZpM7-yGBodA19dXg8eTY-32wDZX_UQ0NAty3qgHDve_hh5DKhPQyvxS-YvYf3n3QHVO2A==?uid=0&filename=fancy_tree.png&disposition=inline&hash=&limit=0&content_type=image%2Fpng&tknv=v2&owner_uid=159868851&size=2048x2048)\n",
    "\n",
    "picture link https://yadi.sk/i/fKgXgTdruFVMng\n",
    "\n",
    "---\n",
    "\n",
    "## Probabilities (sample means)\n",
    "\n",
    "> Before the first split:\n",
    "\n",
    "$$P(y=\\text{BLUE}) = \\frac{9}{20} = 0.45$$\n",
    "\n",
    "$$P(y=\\text{YELLOW}) = \\frac{11}{20} = 0.55$$\n",
    "\n",
    "> After the first split:\n",
    "\n",
    "$$P(y=\\text{BLUE}|X\\leq 12) = \\frac{8}{13} \\approx 0.62$$\n",
    "$$P(y=\\text{BLUE}|X> 12) = \\frac{1}{7} \\approx 0.14$$\n",
    "\n",
    "$$P(y=\\text{YELLOW}|X\\leq 12) = \\frac{5}{13} \\approx 0.38$$\n",
    "$$P(y=\\text{YELLOW}|X > 12) = \\frac{6}{7} \\approx 0.86$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Entropy\n",
    "\n",
    "$$\n",
    "H(p) = - \\sum_i^K p_i\\log(p_i)\n",
    "$$\n",
    "\n",
    "\n",
    "> Before the first split\n",
    "\n",
    "$$H_{\\text{parent}} = - 0.45 \\log 0.45 - 0.55 \\log 0.55 \\approx 0.69 $$\n",
    "\n",
    "> After the first split\n",
    "\n",
    "$$H_{\\text{left}} = - 0.62 \\log 0.62 - 0.38 \\log 0.38 \\approx 0.66$$\n",
    "\n",
    "$$H_{\\text{right}} = - 0.14 \\log 0.14 - 0.86 \\log 0.86 \\approx 0.40$$\n",
    "\n",
    "$$H_{\\text{child}} =  - \\frac{13}{20} 0.66 - \\frac{7}{20} 0.40 \\approx 0.57$$\n",
    "\n",
    "## Information Gain\n",
    "$$\n",
    "IG = H(\\text{parent}) - H(\\text{child})\n",
    "$$\n",
    "\n",
    "\n",
    "$$IG = 0.69 - 0.57 = 0.12$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle's 'Forest Cover Type Prediction' competition\n",
    "\n",
    "Read in the data as pandas dataframes. Data was downloaded as csv files from the Kaggle competition Data page https://www.kaggle.com/c/forest-cover-type-prediction/data.\n",
    "\n",
    "> You could install kaggle package https://github.com/Kaggle/kaggle-api and obtain this dataset by `kaggle competitions download -c forest-cover-type-prediction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data, train an algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public test (we do not have labels for them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful links\n",
    "\n",
    "\n",
    "- All parameters of a DecisionTreeClassifier explained https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
